ä½¿ç”¨ llama.cpp çš„ `llama-server` æ™‚ï¼Œè¨­å®š `--metrics` ä¾†å•Ÿç”¨ Prometheus æ ¼å¼ç›£æ§æŒ‡æ¨™ï¼Œç”¨æ–¼è¿½è¹¤ **LLM çš„æ•ˆèƒ½ç‹€æ³èˆ‡ç•¶å‰ä½‡åˆ—ç‹€æ…‹**ã€‚

æ¨è«–å¼•æ“å•Ÿå‹•å¾Œï¼Œå¯ä»¥å¾ `/metrics` å–å¾—ï¼Œä¾‹å¦‚ï¼š
```bash
$ curl http://localhost:8080/metrics
# HELP llamacpp:prompt_tokens_total Number of prompt tokens processed.
# TYPE llamacpp:prompt_tokens_total counter
llamacpp:prompt_tokens_total 33065
# HELP llamacpp:prompt_seconds_total Prompt process time
# TYPE llamacpp:prompt_seconds_total counter
llamacpp:prompt_seconds_total 235.743
# HELP llamacpp:tokens_predicted_total Number of generation tokens processed.
# TYPE llamacpp:tokens_predicted_total counter
llamacpp:tokens_predicted_total 7801
# HELP llamacpp:tokens_predicted_seconds_total Predict process time
# TYPE llamacpp:tokens_predicted_seconds_total counter
llamacpp:tokens_predicted_seconds_total 279.178
# HELP llamacpp:n_decode_total Total number of llama_decode() calls
# TYPE llamacpp:n_decode_total counter
llamacpp:n_decode_total 7831
# HELP llamacpp:n_busy_slots_per_decode Average number of busy slots per llama_decode() call
# TYPE llamacpp:n_busy_slots_per_decode counter
llamacpp:n_busy_slots_per_decode 1
# HELP llamacpp:prompt_tokens_seconds Average prompt throughput in tokens/s.
# TYPE llamacpp:prompt_tokens_seconds gauge
llamacpp:prompt_tokens_seconds 140.259
# HELP llamacpp:predicted_tokens_seconds Average generation throughput in tokens/s.
# TYPE llamacpp:predicted_tokens_seconds gauge
llamacpp:predicted_tokens_seconds 27.9427
# HELP llamacpp:requests_processing Number of requests processing.
# TYPE llamacpp:requests_processing gauge
llamacpp:requests_processing 0
# HELP llamacpp:requests_deferred Number of requests deferred.
# TYPE llamacpp:requests_deferred gauge
llamacpp:requests_deferred 0
```

---

# å„å€‹æŒ‡æ¨™çš„è©³ç´°è§£é‡‹

## ğŸ“Š ç´¯ç©è¨ˆæ•¸å™¨ï¼ˆcounterï¼‰

é€™äº›æŒ‡æ¨™æœƒä¸æ–·ç´¯åŠ ï¼Œè¡¨ç¤ºè‡ªä¼ºæœå™¨å•Ÿå‹•ä»¥ä¾†çš„ç¸½å€¼ã€‚

### 1. `llamacpp:prompt_tokens_total`

> **èªªæ˜**ï¼šç¸½å…±è™•ç†éçš„ **Prompt tokens** æ•¸é‡ã€‚
> **ç”¨é€”**ï¼šä»£è¡¨ç”¨æˆ¶è¼¸å…¥ï¼ˆpromptï¼‰éƒ¨åˆ†çš„ç¸½ token æ•¸ï¼Œåæ˜ ä½¿ç”¨å¯†é›†åº¦ã€‚

â¡ï¸ **ä¾‹å¦‚**ï¼šè‹¥ä½¿ç”¨è€…é€å‡º 3 æ¬¡ promptï¼Œå„ç‚º 10ã€20ã€30 tokensï¼Œé€™å€‹å€¼æœƒæ˜¯ `60`ã€‚

---

### 2. `llamacpp:prompt_seconds_total`

> **èªªæ˜**ï¼šè™•ç† prompt tokens ç¸½å…±èŠ±è²»çš„æ™‚é–“ï¼ˆç§’ï¼‰ã€‚
> **ç”¨é€”**ï¼šæ­é…ä¸Šé¢ token æ•¸é‡å¯ä¼°ç®—å¹³å‡ throughputã€‚

---

### 3. `llamacpp:tokens_predicted_total`

> **èªªæ˜**ï¼šç¸½å…±ç”¢ç”Ÿï¼ˆæ¨è«–ï¼‰å‡ºçš„ **output tokens** æ•¸é‡ã€‚
> **ç”¨é€”**ï¼šä»£è¡¨æ¨¡å‹å¯¦éš›ç”Ÿæˆçš„æ–‡å­—é‡ã€‚

---

### 4. `llamacpp:tokens_predicted_seconds_total`

> **èªªæ˜**ï¼šç”¨æ–¼æ¨è«– tokens çš„ç¸½è€—æ™‚ã€‚
> **ç”¨é€”**ï¼šå¯è¨ˆç®— **å¹³å‡ç”Ÿæˆé€Ÿç‡**ï¼Œä¾‹å¦‚ tokens per secondã€‚

---

### 5. `llamacpp:n_decode_total`

> **èªªæ˜**ï¼šå‘¼å« `llama_decode()` çš„ç¸½æ¬¡æ•¸ã€‚
> **ç”¨é€”**ï¼šä»£è¡¨æ¨¡å‹è§£ç¢¼éšæ®µçš„è¨ˆç®—æ¬¡æ•¸ï¼Œåæ˜ å¾Œç«¯å£“åŠ›èˆ‡ token-by-token generation è¡Œç‚ºã€‚

---

### 6. `llamacpp:n_busy_slots_per_decode`

> **èªªæ˜**ï¼šæ¯æ¬¡ decode å¹³å‡å¿™ç¢Œçš„ slot æ•¸ï¼ˆæ‰€æœ‰ slot æ˜¯åŸ·è¡Œæ¨è«–è«‹æ±‚çš„ worker contextï¼‰ã€‚
> **ç”¨é€”**ï¼šè©•ä¼°å¤šä»»å‹™ä½µç™¼ç¨‹åº¦æˆ–å…±äº«è¨˜æ†¶å€åˆ©ç”¨ç‡ã€‚

> âš ï¸ é›–ç„¶é€™æ˜¯ counterï¼Œä½†è¡¨ç¤ºçš„æ˜¯ã€Œç´¯ç©ç¸½å’Œã€ï¼Œä¾‹å¦‚ï¼šdecode äº† 3 æ¬¡ï¼Œslot å¿™ç¢Œæ•¸ç‚º 1, 2, 3ï¼Œé‚£é€™é‚Šæœƒæ˜¯ `6`ã€‚

---

## âš¡ å³æ™‚æ•¸å€¼ï¼ˆgaugeï¼‰

é€™é¡æŒ‡æ¨™æœƒå³æ™‚è®Šå‹•ï¼Œåæ˜ ç•¶å‰ç¬é–“çš„ç‹€æ…‹ã€‚

### 7. `llamacpp:prompt_tokens_seconds`

> **èªªæ˜**ï¼š**å¹³å‡ prompt throughput**ï¼ˆtokens/secï¼‰ã€‚
> **ç”¨é€”**ï¼šæ•ˆèƒ½è©•ä¼°ï¼Œå¯ç›£æ§ prompt è¼¸å…¥éšæ®µçš„è™•ç†é€Ÿåº¦ã€‚
> **è¨ˆç®—å¼**ï¼š

```text
llamacpp:prompt_tokens_total / llamacpp:prompt_seconds_total
= 33065 / 235.743 â‰ˆ 140.259
```

---

### 8. `llamacpp:predicted_tokens_seconds`

> **èªªæ˜**ï¼š**å¹³å‡ç”Ÿæˆ throughput**ï¼ˆtokens/secï¼‰ã€‚
> **ç”¨é€”**ï¼šæ¨è«–æ•ˆèƒ½çš„é—œéµæŒ‡æ¨™ï¼Œè‹¥æ•¸å­—ä¸‹é™å¯èƒ½ä»£è¡¨ä¼ºæœå™¨éè¼‰æˆ–æ¨¡å‹æ•ˆèƒ½ç“¶é ¸ã€‚
> **è¨ˆç®—å¼**ï¼š

```text
tokens_predicted_total / tokens_predicted_seconds_total
= 7801 / 279.178 â‰ˆ 27.94
```

---

### 9. `llamacpp:requests_processing`

> **èªªæ˜**ï¼š**ç•¶å‰æ­£åœ¨è™•ç†çš„è«‹æ±‚æ•¸**ï¼ˆä¾‹å¦‚æ­£åœ¨ decodingï¼‰ã€‚
> **ç”¨é€”**ï¼šéå¸¸å¯¦ç”¨çš„å‹•æ…‹è² è¼‰æŒ‡æ¨™ï¼Œ**å¯ç”¨ä¾†åš proxy è·¯ç”±æ±ºç­–**ã€‚æ•¸å€¼è¶Šé«˜ä»£è¡¨è¶Šå¿™ã€‚

---

### 10. `llamacpp:requests_deferred`

> **èªªæ˜**ï¼šå› è³‡æºä¸è¶³ã€slot æ»¿è¼‰è€Œè¢«å»¶å¾Œçš„è«‹æ±‚æ•¸ã€‚
> **ç”¨é€”**ï¼šä»£è¡¨å£“åŠ›ç“¶é ¸ï¼Œè‹¥æ­¤æ•¸å­—éé›¶ï¼Œä»£è¡¨ç•¶ä¸‹æ¨¡å‹å¤ªå¿™å°è‡´æ’éšŠã€‚
> **å»ºè­°**ï¼šæ­é… `requests_processing` ä¸€èµ·ä½¿ç”¨ï¼Œå»ºç«‹é–¾å€¼è­¦ç¤ºæˆ–è² è¼‰ç§»è½‰æ©Ÿåˆ¶ã€‚

---

## ğŸ”§ å°çµï¼šå¯¦å‹™æ‡‰ç”¨å»ºè­°

| æŒ‡æ¨™                                               | å¯¦ç”¨æƒ…å¢ƒ    | å»ºè­°ç”¨é€”                |
| ------------------------------------------------ | ------- | ------------------- |
| `requests_processing`                            | å³æ™‚æµé‡åˆ¤æ–·  | proxy routingï¼ˆæŒ‘æœ€é–’çš„ï¼‰ |
| `requests_deferred`                              | å£“åŠ›ç“¶é ¸    | ç†”æ–·å™¨ã€overload ä¿è­·     |
| `tokens_predicted_seconds`                       | æ¨¡å‹æ•ˆèƒ½è¶¨å‹¢  | é è­¦ / æ™‚é–“çª—åˆ†æ          |
| `prompt_tokens_total` + `tokens_predicted_total` | ä½¿ç”¨é‡çµ±è¨ˆ   | è¨ˆè²»ã€æ—¥èªŒè¨˜éŒ„             |
| `n_busy_slots_per_decode`                        | å¤šä»»å‹™ä½µç™¼è§€å¯Ÿ | slot tuning èª¿åƒä¾æ“š    |


---
---


# å»¶ä¼¸æ‡‰ç”¨
- è¨ˆç®— per minute ä½¿ç”¨è¶¨å‹¢
- ç•¶ `requests_deferred` å‡é«˜æ™‚è‡ªå‹•é™è¼‰
- åˆ©ç”¨ Grafana è¦–è¦ºåŒ–æ‰€æœ‰æŒ‡æ¨™

---

## âœ… 1. è¨ˆç®—ã€Œæ¯åˆ†é˜ä½¿ç”¨è¶¨å‹¢ã€

### ğŸ¯ ç›®æ¨™

å¾ `/metrics` æŒ‡æ¨™ä¸­æ¨ç®—ã€Œéå» 1 åˆ†é˜çš„ tokens è™•ç†é‡ã€æˆ–ã€Œæ¨è«– throughputã€ï¼Œä¾‹å¦‚ï¼š

* æ¯åˆ†é˜ prompt token æ•¸
* æ¯åˆ†é˜ç”Ÿæˆ token æ•¸
* æ¯åˆ†é˜å¹³å‡ latency

### ğŸ§  åŸç†

Prometheus çš„ counter æ˜¯ç´¯ç©å€¼ï¼ˆä¾‹å¦‚ `llamacpp:tokens_predicted_total`ï¼‰ï¼Œä½† Prometheus æœ¬èº«æ”¯æ´å°é€™é¡ counter åšæ™‚é–“å·®çš„æŸ¥è©¢ï¼š

### ğŸ“Œ Prometheus Query å¯«æ³•

```promql
rate(llamacpp:tokens_predicted_total[1m])
```

* `rate(...)`ï¼šè¨ˆç®—æ¯ç§’å¢é‡ï¼ˆæ»‘å‹•æ™‚é–“çª—å¹³å‡ï¼‰ã€‚
* `[...]`ï¼šè¡¨ç¤ºæ™‚é–“çª—ï¼Œä¾‹å¦‚ 1 åˆ†é˜ã€‚
* è‹¥æƒ³æ›æˆã€Œæ¯åˆ†é˜ã€token æ•¸ï¼Œå¯ä¹˜ä»¥ 60ï¼š

```promql
rate(llamacpp:tokens_predicted_total[1m]) * 60
```

å…¶ä»–é¡ä¼¼ç”¨æ³•ï¼š

```promql
# æ¯åˆ†é˜ prompt token æ•¸
rate(llamacpp:prompt_tokens_total[1m]) * 60

# éå» 5 åˆ†é˜ average throughput
avg(rate(llamacpp:tokens_predicted_total[5m]) * 60)
```

### ğŸ§ª å¯¦ä½œæ–¹å¼

åªè¦æŠŠ llama-server `/metrics` æ›å…‰çµ¦ Prometheusï¼ˆä¸‹é¢ç¬¬ 3 é»æœƒèªªæ˜ï¼‰ï¼Œå°±å¯ä»¥ç›´æ¥åœ¨ Grafana æˆ– AlertManager ä¸Šè¨­å®šæ¯åˆ†é˜ä½¿ç”¨è¶¨å‹¢åœ–è¡¨èˆ‡è­¦ç¤ºã€‚

---

## ğŸš¨ 2. ç•¶ `requests_deferred` å‡é«˜æ™‚è‡ªå‹•é™è¼‰ï¼ˆOverload ä¿è­·ï¼‰

### ğŸ¯ ç›®æ¨™

ç•¶æŸä¸€å° llama-server å¤ªå¿™ï¼ˆä½‡åˆ—å·²æ»¿ï¼‰æ™‚ï¼Œè‡ªå‹•ï¼š

* æ‹’çµ•æ–°è«‹æ±‚
* æŠŠè«‹æ±‚è·¯ç”±åˆ°å…¶ä»– backend
* æˆ–å›å‚³ 503 éŒ¯èª¤ï¼ˆsoft failï¼‰

### ğŸ§  åˆ¤æ–·æ¢ä»¶

| æŒ‡æ¨™                        | åˆ¤æ–·æ„ç¾©             |
| ------------------------- | ---------------- |
| `requests_processing` â‰¥ N | è¡¨ç¤ºæ­£åœ¨è™•ç†å¾ˆå¤šè«‹æ±‚ï¼ˆè² è¼‰é«˜ï¼‰  |
| `requests_deferred` > 0   | **ä»£è¡¨æ¨¡å‹å·²æ»¿è¼‰ï¼Œæ’ä¸é€²å»** |

### ğŸ§° Proxy å¯¦ä½œæ–¹å¼ï¼ˆç°¡åŒ–ï¼‰

```py
# éè¼‰ä¿è­·æ¢ä»¶
MAX_ALLOWED_DEFERRED = 2

# åœ¨ fetch_metrics() è£¡åŠ å…¥æ¢ä»¶
if 'llamacpp:requests_deferred' in family.name:
    deferred = family.samples[0].value
    if deferred >= MAX_ALLOWED_DEFERRED:
        ready = False  # å³ä½¿ health OKï¼Œä¹Ÿæ’é™¤
```

é€™æ¨£å°±èƒ½è®“ proxyã€Œè­˜åˆ¥å‡ºéè¼‰ç¯€é»ã€ä¸¦è‡ªå‹•ç•¥éã€‚

### ğŸ” æ›´é€²ä¸€æ­¥ï¼šå‹•æ…‹é™æµ

ä½ ç”šè‡³å¯ä»¥è¨­å®šåœ¨ deferred ä¸Šå‡æ™‚æ¸›å°‘æ¯å°å…è¨±çš„ concurrent è«‹æ±‚æ•¸ï¼Œåšåˆ° soft é™æµï¼Œæˆ–åœ¨ Nginx å±¤ç´šè¨­å®šå¾Œç«¯å¤±æ•—é‡è©¦ã€‚

---

## ğŸ“Š 3. ä½¿ç”¨ Grafana è¦–è¦ºåŒ– llama-server æŒ‡æ¨™

### ğŸ§± æ¶æ§‹éœ€æ±‚

ä½ éœ€è¦ä»¥ä¸‹ä¸‰å€‹å…ƒä»¶ï¼š

1. **Prometheus**ï¼šæ”¶é›† `/metrics` æŒ‡æ¨™
2. **Grafana**ï¼šåšè¦–è¦ºåŒ–å„€è¡¨æ¿
3. **llama-server**ï¼šå·²é–‹å•Ÿ `--metrics`ï¼Œä¸¦èƒ½è¢« Prometheus æŠ“å–

### ğŸ“¦ Prometheus è¨­å®šç¯„ä¾‹ `prometheus.yml`

```yaml
scrape_configs:
  - job_name: 'llamacpp'
    static_configs:
      - targets: ['llm-0:8080', 'llm-1:8080']
```

> åªè¦é€™äº› targets èƒ½æŠ“åˆ° `/metrics` é é¢ï¼ˆllama-server æœ‰å•Ÿ `--metrics`ï¼‰ï¼ŒPrometheus å°±æœƒé–‹å§‹æ”¶è³‡æ–™ã€‚

ä½ å¯ä»¥ç”¨ `docker-compose` æŠŠ Prometheus åŠ å…¥ç¾æœ‰æ¶æ§‹ï¼ˆæˆ‘å¯å¹«ä½ é…ç½®ï¼‰ã€‚

---

### ğŸ“Š Grafana Dashboard å»ºè­°åœ–è¡¨

| åœ–è¡¨                    | PromQL æŸ¥è©¢èªæ³•                                 | èªªæ˜       |
| --------------------- | ------------------------------------------- | -------- |
| Prompt Token æ¯ç§’       | `rate(llamacpp:prompt_tokens_total[1m])`    | è¼¸å…¥é‡      |
| Generation Token æ¯ç§’   | `rate(llamacpp:tokens_predicted_total[1m])` | è¼¸å‡ºé‡      |
| Prompt throughput     | `llamacpp:prompt_tokens_seconds`            | å³æ™‚       |
| Generation throughput | `llamacpp:predicted_tokens_seconds`         | å³æ™‚       |
| Requests processing   | `llamacpp:requests_processing`              | å¯åš alert |
| Requests deferred     | `llamacpp:requests_deferred`                | éè¼‰æŒ‡æ¨™     |

---

### ğŸ“Œ ç¯„ä¾‹åœ–ç¤º

ä½ å¯ä»¥ç”¨ã€ŒStatã€æˆ–ã€ŒTime seriesã€å…ƒä»¶ç•«å‡ºï¼š

* æ¯å° server çš„ token throughput è¶¨å‹¢
* Slot ä½¿ç”¨ç‡ï¼ˆbusy slotsï¼‰
* éå» 1 åˆ†é˜å¹³å‡æ¨è«–é€Ÿç‡
* Deferred è­¦ç¤ºé–¾å€¼ï¼ˆç´…è‰²ï¼‰

---

## âœ… çµèªèˆ‡å»ºè­°

| é …ç›®         | å»ºè­°å·¥å…·                         | å‚™è¨»                   |
| ---------- | ---------------------------- | -------------------- |
| ç›£æ§ + åœ–è¡¨    | Prometheus + Grafana         | æœ€ç©©å®šä¸”ç¤¾ç¾¤æ´»èº             |
| Proxy è·¯ç”±ç­–ç•¥ | FastAPI + `/metrics` å¿«å–      | å¯åŠ ä¸Š weighted routing |
| è­¦ç¤ºé€šçŸ¥       | Grafana Alert æˆ– AlertManager | å¯æ¥ Slackã€Email       |
